{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, urllib, gzip\n",
    "from __future__ import print_function\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg') # Change matplotlib backend, in case we have no X server running..\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 630M (CNMeM is disabled, cuDNN not available)\n",
      "/home/igor/.local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer,DropoutLayer\n",
    "from lasagne.nonlinearities import rectify, leaky_rectify, tanh, softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from lasagne.objectives import categorical_crossentropy\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator, PrintLayerInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lasagne.layers (slower)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import Conv2DLayer as Conv2DLayerSlow\n",
    "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerSlow\n",
    "try:\n",
    "    from lasagne.layers.cuda_convnet import Conv2DCCLayer as Conv2DLayerFast\n",
    "    from lasagne.layers.cuda_convnet import MaxPool2DCCLayer as MaxPool2DLayerFast\n",
    "    print('Using cuda_convnet (faster)')\n",
    "except ImportError:\n",
    "    from lasagne.layers import Conv2DLayer as Conv2DLayerFast\n",
    "    from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerFast\n",
    "    from lasagne.layers import Pool2DLayer\n",
    "    print('Using lasagne.layers (slower)')\n",
    "\n",
    "g_pictures_cnt=0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_width = 28\n",
    "region_height = 28\n",
    "\n",
    "g_split_lines = 8\n",
    "g_split_cols = 8\n",
    "\n",
    "an_min=-3\n",
    "an_max=3\n",
    "\n",
    "g_mode=3 # color mode 2 without black\n",
    "g_colors=3\n",
    "G_trash=1 #trashhold input picture\n",
    "G_trash_learn=1 #trashhold learn picture\n",
    "g_zca_mode=0 #whitening enabled\n",
    "g_zca_epsilon=0.1\n",
    "\n",
    "\n",
    "g_conv_num_filters = 16\n",
    "g_filter_size = 3\n",
    "g_pool_size = 2\n",
    "g_dense_mid_size = 256\n",
    "g_stride=1\n",
    "g_encode_size = 32\n",
    "\n",
    "g_classifall=2\n",
    "\n",
    "g_ill='all'\n",
    "fn_weight='conv_ae_medical200_'+g_ill+'ColorReg.pkl'\n",
    "g_last_layerC2D=(((region_width-(g_filter_size-g_stride))/g_stride-(g_filter_size-g_stride))/g_stride/g_pool_size-(g_filter_size-g_stride))/g_stride/g_pool_size\n",
    "g_max_epochs=500\n",
    "g_dir_out='medical_out'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zca_whitening_BW(matrix,epsilon = 0.1 ):\n",
    "    l_h    =matrix.shape[0];\n",
    "    l_w    =matrix.shape[1];\n",
    "    inputs = matrix.flatten(1)\n",
    "    \n",
    "    inputs = inputs.reshape(1, len(inputs))\n",
    "    \n",
    "    sigma = np.dot(inputs, inputs.T)/inputs.shape[1] #Correlation matrix\n",
    "    U,S,V = np.linalg.svd(sigma) #Singular Value Decomposition\n",
    "    #epsilon = 0.1                #Whitening constant, it prevents division by zero\n",
    "    ZCAMatrix = np.dot(np.dot(U, np.diag(1.0/np.sqrt(np.diag(S) + epsilon))), U.T)                     \n",
    "    #ZCA Whitening matrix\n",
    "    #l_res=np.clip(np.dot(ZCAMatrix, inputs)*256., a_min = 0, a_max = 255).astype('uint8')\n",
    "    l_res=np.dot(ZCAMatrix, inputs)\n",
    "    \n",
    "    return l_res.reshape(l_h,l_w).T   #Data whitening\n",
    "\n",
    "def zca_whitening_color(inputs,epsilon = 0.1 ):\n",
    "    if len(inputs.shape)==3:\n",
    "        if g_colors==1:\n",
    "            gray_image = inputs\n",
    "        else:\n",
    "            gray_image = np.dot(inputs[..., :3], [0.299, 0.587, 0.114])\n",
    "        #print (gray_image.shape)\n",
    "        vv3=zca_whitening_BW(gray_image,epsilon = epsilon)\n",
    "        for jjj in range(3):\n",
    "            #print(\"jjj\",jjj)\n",
    "            if jjj==0:\n",
    "                dd4 =vv3.reshape(1,vv3.shape[0],vv3.shape[1])\n",
    "            else:    \n",
    "                dd4 =np.vstack((dd4,vv3.reshape(1,vv3.shape[0],vv3.shape[1])))\n",
    "            \n",
    "            \n",
    "            #print (\"vv3\",vv3.shape)\n",
    "            #print (\"dd4\",dd4.shape)\n",
    "        return np.rollaxis(dd4, 0, 3)\n",
    "    \n",
    "    elif len(inputs.shape)==2:        \n",
    "        #print(\"bw_mode\")\n",
    "        return zca_whitening_BW(inputs,epsilon = epsilon)\n",
    "    else:\n",
    "        print(\"unk mode\",inputs.shape)\n",
    "        \n",
    "def f_ill4fname(p_fname):\n",
    "        if 'geman' in p_fname or 'dobro' in p_fname :\n",
    "            return 1\n",
    "        elif 'gemat' in p_fname or 'gepatom' in p_fname or  'krov' in p_fname or 'arhi' in p_fname or 'hype' in p_fname :\n",
    "            return 2\n",
    "        elif 'kist' in p_fname:\n",
    "            return 3\n",
    "        elif 'gepati' in p_fname or 'ciro' in p_fname:\n",
    "            return 4\n",
    "        elif 'meta' in p_fname or 'aden' in p_fname  or 'rak' in p_fname or 'karci' in p_fname or 'opuh'  in p_fname :\n",
    "            return 5  \n",
    "        elif 'ehin' in p_fname or 'echin' in p_fname:\n",
    "            return 6  \n",
    "        elif 'gepatoz' in p_fname or 'distr' in p_fname or 'asci' in p_fname:\n",
    "            return 7  \n",
    "        elif 'norm' in p_fname :\n",
    "            return 0\n",
    "        elif '-on' in p_fname :\n",
    "            return 10\n",
    "        elif '-off' in p_fname :\n",
    "            return 11\n",
    "        else:\n",
    "            return 0\n",
    "  \n",
    "        \n",
    "def f_color4fname(p_fname):\n",
    "    l_illN=f_ill4fname(p_fname)\n",
    "    if not not g_ill and g_ill!='all':\n",
    "        if (g_ill=='meta' and l_illN==5)\\\n",
    "            or (g_ill=='dobro' and l_illN==1) \\\n",
    "            or (g_ill=='ciroz' and l_illN==4) \\\n",
    "            or (g_ill=='kista' and l_illN==3) \\\n",
    "            or (g_ill=='echino' and l_illN==6) \\\n",
    "            or (g_ill=='distro' and l_illN==7) \\\n",
    "            or (g_ill=='krov' and l_illN==2) :\n",
    "            return [0,0,1]\n",
    "        elif l_illN==0:\n",
    "            return [-1,-1,-1]\n",
    "        else:    \n",
    "            return [0,0,0]\n",
    "    else:\n",
    "        #print('point4 '+p_fname)\n",
    "        if l_illN==1:\n",
    "            return [0,0,1]\n",
    "        elif l_illN==2 :\n",
    "            return [0,1,1]\n",
    "        elif l_illN==3:\n",
    "            return [1,0,1]\n",
    "        elif l_illN==4:\n",
    "            return [1,1,0]\n",
    "        elif l_illN==6:\n",
    "            return [0,1,0]\n",
    "        elif l_illN==7:\n",
    "            return [0,1,0]\n",
    "        elif l_illN==5:\n",
    "            return [1,0,0]    \n",
    "        elif  l_illN==0:\n",
    "            return [-1,-1,-1]\n",
    "        else:\n",
    "            return [1,1,1]\n",
    "\n",
    "    \n",
    "\n",
    " \n",
    "        \n",
    "def get_pictures2np(dir_reg='pechen1_reg',dir_100='pechen224',p_width_from=0,p_width_delta=0,p_height_from=0,p_height_delta=0):\n",
    "    l_rw=region_width*g_split_cols\n",
    "    l_rh=region_height*g_split_lines\n",
    "    l_rS=l_rw*l_rh\n",
    "    y_region=[]\n",
    "    y_classif=[]\n",
    "    x_original=[]\n",
    "    fnames=[]\n",
    "    global g_pictures_cnt\n",
    "\n",
    "    example_file = [f for f in glob.glob(os.path.join(dir_100,'*.*')) if \".JPG\" in f or \".jpg\" in f or \".png\" in f or \".\" in f]\n",
    "            \n",
    "    \n",
    "    g_pictures_cnt=0\n",
    "    for f_example in example_file:\n",
    "        #im = scipy.misc.imread(f)\n",
    "        f_region=os.path.join(dir_reg,os.path.basename(f_example))\n",
    "        #print ('f_example='+f_example)\n",
    "        if os.path.exists(f_region) or not dir_reg:\n",
    "            l_col=f_color4fname(f_example)\n",
    "            l_illN=f_ill4fname(f_example)\n",
    "            if not not g_ill and l_col==[0,0,0] and g_ill!='all':\n",
    "                continue\n",
    "            if l_col==[-1,-1,-1] and g_mode==0:\n",
    "                l_col=[0,0,0]\n",
    "            elif l_col==[-1,-1,-1] and g_mode==2:\n",
    "                l_col=[1,1,1]\n",
    "                \n",
    "            print (str(g_pictures_cnt)+'->  '+f_example+' '+str(l_illN),l_col)\n",
    "            #y_classif.extend([l_illN])\n",
    "            l_tmp=np.zeros(g_classifall)\n",
    "            l_tmp[l_illN%10]=1\n",
    "            y_classif.extend([l_tmp])\n",
    "            g_pictures_cnt+=1\n",
    "            fnames.extend([os.path.basename(f_example)])\n",
    "            \n",
    "            im_orig00=Image.open(f_example)\n",
    "                \n",
    "            if p_width_from>0 and p_width_delta==0:\n",
    "                l_widthF = im_orig00.size[0]\n",
    "                l_heightF = im_orig00.size[1]\n",
    "                im_orig00=im_orig00.crop((int(l_widthF*p_width_from),int(l_heightF*p_height_from),l_widthF-1,l_heightF-1))\n",
    "            elif p_width_from>0 and p_width_delta>0:    \n",
    "                l_widthF = im_orig00.size[0]\n",
    "                l_heightF = im_orig00.size[1]\n",
    "                im_orig00=im_orig00.crop((l_widthF-int(l_widthF*p_width_from),0,\\\n",
    "                                          l_widthF+int(l_widthF*(p_width_delta-p_width_from))-1,l_heightF-1))\n",
    "     \n",
    "    \n",
    "            if not not dir_reg:\n",
    "                im_region00  = Image.open(f_region)\n",
    "                if p_width_from>0 and p_width_delta==0:\n",
    "                    l_widthF = im_region00.size[0]\n",
    "                    l_heightF = im_region00.size[1]\n",
    "                    im_region00=im_region00.crop((int(l_widthF*p_width_from),int(l_heightF*p_height_from),\\\n",
    "                                                  l_widthF-1,l_heightF-1))\n",
    "                elif p_width_from>0 and p_width_delta>0:    \n",
    "                    l_widthF = im_region00.size[0]\n",
    "                    l_heightF = im_region00.size[1]\n",
    "                    im_region00=im_region00.crop((l_widthF-int(l_widthF*p_width_from),0,\\\n",
    "                                                  l_widthF+int(l_widthF*(p_width_delta-p_width_from))-1,l_heightF-1))\n",
    "            else: \n",
    "                im_region00  = im_orig00\n",
    "\n",
    "            \n",
    "            if g_zca_mode==1:\n",
    "                im_orig=Image.fromarray(zca_whitening_color(np.array(im_orig00),epsilon = g_zca_epsilon))\n",
    "                im_region=Image.fromarray(zca_whitening_color(np.array(im_region00),epsilon = g_zca_epsilon ))\n",
    "            else:\n",
    "                im_orig=im_orig00\n",
    "                im_region=im_region00\n",
    "                \n",
    "            l_im_orig3 = np.array(im_orig.resize((l_rw, l_rh), Image.BILINEAR)).reshape(l_rS,-1) # linear interpolation in a 2x2 environment\n",
    "            l_im_reg3  = np.array(im_region.resize((l_rw, l_rh), Image.BILINEAR)).reshape(l_rS,-1)     # linear interpolation in a 2x2 environment\n",
    "            im4 = []\n",
    "            if l_im_orig3.shape[1]==1:\n",
    "                l_im_orig0=l_im_orig3\n",
    "                l_im_orig3=np.hstack((l_im_orig3,l_im_orig0))\n",
    "                l_im_orig3=np.hstack((l_im_orig3,l_im_orig0))\n",
    "            if l_im_reg3.shape[1]==1:\n",
    "                l_im_reg0=l_im_reg3\n",
    "                l_im_reg3=np.hstack((l_im_reg3,l_im_reg0))\n",
    "                l_im_reg3=np.hstack((l_im_reg3,l_im_reg0))\n",
    "\n",
    "            for pix in range(l_rS) :\n",
    "                d00=[0,0,0]\n",
    "                if (g_mode==0 or g_mode==1) and ( l_im_reg3[pix][0]>G_trash_learn or l_im_reg3[pix][0]> l_im_orig3[pix][0]) and (l_im_orig3[pix][0]>=G_trash):\n",
    "                    d00=[l_im_orig3[pix][0]*l_col[0],l_im_orig3[pix][0]*l_col[1],l_im_orig3[pix][0]*l_col[2]]\n",
    "                elif g_mode==2  and (l_im_orig3[pix][0]>=G_trash or l_im_orig3[pix][1]>=G_trash or l_im_orig3[pix][2]>=G_trash):\n",
    "                    if (l_im_reg3[pix][0]>G_trash_learn or l_im_reg3[pix][0]> l_im_orig3[pix][0]):\n",
    "                        d00=[l_im_orig3[pix][0]*l_col[0],l_im_orig3[pix][0]*l_col[1],l_im_orig3[pix][0]*l_col[2]]\n",
    "                    else:\n",
    "                        d00=[l_im_orig3[pix][0]/4,l_im_orig3[pix][0]/4,l_im_orig3[pix][0]/4]\n",
    "                elif g_mode==3:\n",
    "                    if l_col==[-1,-1,-1]:\n",
    "                        d00=[l_im_orig3[pix][0]/2,l_im_orig3[pix][0]/2,l_im_orig3[pix][0]/2]\n",
    "                    elif (l_im_orig3[pix][0]>=G_trash or l_im_orig3[pix][1]>=G_trash or l_im_orig3[pix][2]>=G_trash):\n",
    "                        if (l_im_reg3[pix][0]>G_trash_learn or l_im_reg3[pix][0]> l_im_orig3[pix][0]):\n",
    "                            d00=[l_im_orig3[pix][0]*l_col[0],l_im_orig3[pix][0]*l_col[1],l_im_orig3[pix][0]*l_col[2]]\n",
    "                        else:\n",
    "                            d00=[l_im_orig3[pix][0]/2,l_im_orig3[pix][0]/2,l_im_orig3[pix][0]/2]\n",
    "                       \n",
    "                if g_colors==1:\n",
    "                    im4.extend([d00[0]])    \n",
    "                else:    \n",
    "                    im4.extend(d00)    \n",
    "                \n",
    "            y_region.extend([im4])\n",
    "            if l_im_orig3.shape[1]==1:\n",
    "                d1=np.array(zip(l_im_orig3,l_im_orig3  ,l_im_orig3))\n",
    "            else:\n",
    "                d1=np.array(l_im_orig3)\n",
    "            if g_colors==1:\n",
    "                x_original.extend([d1[:,0].reshape(-1,1)])\n",
    "                #c=b[:,1].reshape(-1,1)            \n",
    "            else:\n",
    "                x_original.extend([d1])\n",
    "        else:\n",
    "            print (\" no file \"+f_example)\n",
    "    return fnames,np.array(x_original).reshape(g_pictures_cnt,l_rh,l_rw,-1),\\\n",
    "           np.array(y_region).reshape(g_pictures_cnt,l_rh,l_rw,-1),\\\n",
    "           np.array(y_classif, dtype=np.float32).reshape(g_pictures_cnt,-1)\n",
    "\n",
    "# rotate image and split it for n tiles        \n",
    "def get_transformedImgages(P_images,p_angle=1):\n",
    "    destImages=[]\n",
    "    for ii1 in range(P_images.shape[0]):\n",
    "        if g_colors==1:\n",
    "            l_image=np.uint8(P_images[ii1]).reshape(P_images.shape[1],P_images.shape[2])\n",
    "        else:\n",
    "            l_image=np.uint8(P_images[ii1])\n",
    "        if p_angle!=0:\n",
    "            im21= np.array(Image.fromarray(l_image).rotate(p_angle))\n",
    "        else:\n",
    "            im21= np.array(Image.fromarray(l_image))\n",
    "        if (g_split_lines<2 and g_split_cols<2):\n",
    "            destImages.extend([im21])\n",
    "        else:\n",
    "            for dy in range(g_split_lines):\n",
    "                for dx in range(g_split_cols):\n",
    "                    y1=dy*region_height\n",
    "                    x1=dx*region_width\n",
    "                    y2=y1+region_height\n",
    "                    x2=x1+region_width\n",
    "                    im22=im21[y1:y2,x1:x2]\n",
    "                    destImages.extend([im22])\n",
    "\n",
    "\n",
    "\n",
    "    destImages=np.array(destImages)\n",
    "    if g_colors==1:\n",
    "        return destImages.reshape(destImages.shape[0],destImages.shape[1],destImages.shape[2],1)    \n",
    "    else:\n",
    "        return destImages    \n",
    "\n",
    "def get_transformedData(p_x_orig,p_y_reg,p_y_classif):\n",
    "    l_X=[]\n",
    "    l_y=[]\n",
    "    l_y_classif=[]\n",
    "    for an in np.arange(an_min,an_max):\n",
    "        rot_orig=get_transformedImgages(p_x_orig,p_angle=an)\n",
    "        for ii1 in range(rot_orig.shape[0]):\n",
    "            d0=rot_orig[ii1]\n",
    "            if g_colors==1:\n",
    "                d1=np.rollaxis((d0)/256., 2, 0)\n",
    "            else:\n",
    "                d1=np.rollaxis((d0)/256., 2, 0)\n",
    "            l_X.extend([d1])\n",
    "    \n",
    "        rot_reg =get_transformedImgages(p_y_reg,p_angle=an)\n",
    "        for ii1 in range(rot_reg.shape[0]):\n",
    "            d0=rot_reg[ii1]\n",
    "            d1=np.rollaxis((d0)/256., 2, 0)\n",
    "            l_y.extend([d1])\n",
    "        \n",
    "        for ii1 in range(p_y_classif.shape[0]):\n",
    "            l_y_classif.extend([p_y_classif[ii1]])\n",
    "        \n",
    "\n",
    "    return np.asarray(l_X, dtype=np.float32),np.asarray(l_y, dtype=np.float32),np.asarray(l_y_classif, dtype=np.float32)\n",
    "\n",
    "\n",
    "def getNTile(p_NN=0,p_dx=0,p_dy=0,p_angle=0):\n",
    "    #print ('getNTile p_NN,p_dx,p_dy,p_angle,g_pictures_cnt ->',p_NN,p_dx,p_dy,p_angle,g_pictures_cnt)\n",
    "    l_angleIdx=p_angle-an_min\n",
    "    l_GlobalOffset=(l_angleIdx)*g_pictures_cnt*g_split_lines\n",
    "    #print('l_GlobalOffset',l_GlobalOffset)\n",
    "\n",
    "    l_NNOffset=p_NN*g_split_lines\n",
    "    l_YOffset=p_dy*g_split_cols ## ???\n",
    "    l_XOffset=p_dx\n",
    "    return l_GlobalOffset+l_NNOffset+l_YOffset+l_XOffset\n",
    "\n",
    "\n",
    "def GetWholeIdxes(p_NN=0,p_angle=0):\n",
    "    idxes=[]\n",
    "    for dy in range(g_split_lines):\n",
    "        for dx in range(g_split_cols):\n",
    "            idxes.extend([getNTile(p_NN=p_NN,p_dx=dx,p_dy=dy,p_angle=p_angle)])\n",
    "    return np.array(idxes)             \n",
    "\n",
    "def GetWholeFrames(p_Xcolor,p_nn,p_angle=0):\n",
    "    idxes1=GetWholeIdxes(p_NN=p_nn,p_angle=p_angle)\n",
    "    #print('idxes1 ',idxes1)\n",
    "    X_input=[]\n",
    "    for idx in idxes1:\n",
    "        X_input.extend(p_Xcolor[idx])\n",
    "    X_input222=np.array(X_input).reshape(-1,g_colors,  region_height,region_width)\n",
    "    return X_input222\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PredictByWholeImg(p_Xcolor,p_nn,p_angle=0):\n",
    "    X_input2=GetWholeFrames(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    X_out22 = ae.predict(X_input2).reshape(-1,g_colors, region_width, region_height)\n",
    "    return X_out22 \n",
    "\n",
    "\n",
    "def AssembleImage(p_FramesImage):\n",
    "    #print(\"p_FramesImage=\",p_FramesImage.shape) \n",
    "    #l_region_width =p_FramesImage.shape[2]\n",
    "    l_region_width =p_FramesImage.shape[3]\n",
    "    #print('l_region_width =',l_region_width)\n",
    "    #l_region_height=p_FramesImage.shape[3]\n",
    "    l_region_height=p_FramesImage.shape[2]\n",
    "    #print('l_region_height =',l_region_height)\n",
    "    l_colors=p_FramesImage.shape[1]\n",
    "    #print(\"l_colors=\",l_colors) \n",
    "    \n",
    "    if (l_colors==3):\n",
    "        dst_im22 = Image.new(\"RGB\", (g_split_cols*l_region_width,g_split_lines*l_region_height), \"red\" )\n",
    "    elif (l_colors==1):    \n",
    "        dst_im22 = Image.new(\"L\", (g_split_cols*l_region_width,g_split_lines*l_region_height), (0) )\n",
    "    elif (l_colors==4):    \n",
    "        dst_im22 = Image.new(\"RGBA\", (g_split_cols*l_region_width,g_split_lines*l_region_height), \"blue\" )\n",
    "\n",
    "    for dy in range(g_split_lines):\n",
    "        for dx in range(g_split_cols):\n",
    "            #print('dy dx',dy,dx)\n",
    "            im1=np.uint8(np.rollaxis(p_FramesImage[dy*g_split_cols+dx], 0, 3)*256.)\n",
    "            #print('im1=',im1.shape)\n",
    "            im1= np.clip(im1, a_min = 0, a_max = 255)\n",
    "            im1  = im1.astype('uint8')\n",
    "            if (l_colors==1):\n",
    "                #rot=Image.fromarray(im1.reshape(l_region_width,l_region_height))\n",
    "                rot=Image.fromarray(im1.reshape(l_region_height,l_region_width))\n",
    "            else:\n",
    "                rot=Image.fromarray(im1)\n",
    "            dst_im22.paste( rot, (dx*l_region_width, dy*l_region_height)) \n",
    "    return np.array(dst_im22)  \n",
    "\n",
    "def GetPicture(p_Xcolor,p_nn,p_angle=0):\n",
    "    #print ('GetPicture.p_Xcolor',p_Xcolor.shape)\n",
    "    X_input2=GetWholeFrames(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    dst_im22=AssembleImage(X_input2)\n",
    "    return dst_im22  \n",
    "\n",
    "def PredictByWholeImgFull(p_Xcolor,p_nn,p_angle=0):\n",
    "    X_out22 = PredictByWholeImg(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    dst_im22=AssembleImage(X_out22)\n",
    "    return dst_im22  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MergePredict_Original(p_original,p_predict):\n",
    "    l_rw=region_width*g_split_cols\n",
    "    l_rh=region_height*g_split_lines\n",
    "    l_rS=l_rw*l_rh\n",
    "    l_colors=p_original.shape[2]\n",
    "    if g_mode==1:\n",
    "        l_blend_img = Image.blend(Image.fromarray(p_original.astype('uint8')), \n",
    "                             Image.fromarray(p_predict), 0.5)\n",
    "\n",
    "        return np.array(l_blend_img)\n",
    "    else:\n",
    "        l_region_width=p_original.shape[0]\n",
    "        l_region_height=p_original.shape[1]\n",
    "        im11 = p_original.reshape(l_region_width*l_region_height,-1) \n",
    "        im3  = p_predict.reshape(l_region_width*l_region_height,-1) \n",
    "    \n",
    "        im4=[]\n",
    "        for pix in range(l_rS) :\n",
    "            if im3[pix][0]>10   :\n",
    "                if l_colors==1:\n",
    "                    im4.extend([im11[pix][0],im11[pix][0]/4,im11[pix][0]/4])\n",
    "                else:    \n",
    "                    im4.extend([im11[pix][0],im11[pix][1]/4,im11[pix][2]/4])\n",
    "            else:\n",
    "                if l_colors==1:\n",
    "                    im4.extend([im11[pix][0],im11[pix][0],im11[pix][0]])\n",
    "                else:    \n",
    "                    im4.extend(im11[pix])\n",
    "        if l_colors==1:\n",
    "            return  np.array(im4).reshape(p_original.shape[0],p_original.shape[1],3).astype('uint8')        \n",
    "        else:    \n",
    "            return  np.array(im4).reshape(p_original.shape[0],p_original.shape[1],p_original.shape[2]).astype('uint8')        \n",
    "\n",
    "\n",
    "def get_layer_by_name(net, name):\n",
    "    for i, layer in enumerate(net.get_all_layers()):\n",
    "        if layer.name == name:\n",
    "            return layer, i\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def print_layers(net):\n",
    "    for i, layer in enumerate(net.get_all_layers()):\n",
    "        print( layer.name, i)\n",
    "\n",
    "def encode_input(encode_layer, X):\n",
    "    return get_output(encode_layer, inputs=X).eval()\n",
    "\n",
    "def predictLayer(p_net,p_layerName,p_Xcolor,p_nn,p_angle=0,p_layerFrom=0,p_layers=4):\n",
    "    l_encode_layer, l_encode_layer_index = get_layer_by_name(p_net, p_layerName)\n",
    "    l_X_input222=GetWholeFrames(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    l_X_encoded = encode_input(l_encode_layer, l_X_input222)\n",
    "    print ('predictLayer '+p_layerName+' ',l_X_encoded.shape)\n",
    "    l_X_encoded2=l_X_encoded[:,p_layerFrom:p_layerFrom+p_layers,:,:]\n",
    "    l_res=AssembleImage(l_X_encoded2)\n",
    "    return l_res \n",
    "    \n",
    "\n",
    "def predictLayersToFile(p_net,p_layerName,p_Xcolor,p_nn,p_angle=0,N_epoch=1,diroutput=g_dir_out):\n",
    "    l_encode_layer, l_encode_layer_index = get_layer_by_name(p_net, p_layerName)\n",
    "    l_X_input222=GetWholeFrames(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    l_X_encoded = encode_input(l_encode_layer, l_X_input222)\n",
    "    dst_im44 = Image.new(\"L\", (g_split_cols*l_X_encoded.shape[2]*l_X_encoded.shape[1],g_split_lines*l_X_encoded.shape[3]), (0) )\n",
    "    l_name='layer_'+p_layerName+'_'+str(p_nn)+'_'+str(N_epoch)+'.png'\n",
    "    f_outf=os.path.join(g_dir_out,os.path.basename(l_name))\n",
    "    \n",
    "\n",
    "    for l_feature in range(l_X_encoded.shape[1]):\n",
    "        l_X_encoded2=l_X_encoded[:,l_feature:l_feature+1,:,:]\n",
    "        l_res=AssembleImage(l_X_encoded2)\n",
    "        l_ResIm=Image.fromarray(l_res)\n",
    "        dst_im44.paste( l_ResIm, (l_feature*g_split_cols*l_X_encoded.shape[2], 0)) \n",
    "    dst_im44.save(f_outf)\n",
    "    \n",
    "    #l_pred_out=PredictByWholeImgFull(p_Xcolor=p_Xcolor,p_nn=p_nn,p_angle=p_angle)\n",
    "    #l_ResIm=Image.fromarray(l_res)\n",
    "    #l_name='layer_predict_'+str(p_nn)+'_'+str(N_epoch)+'.png'\n",
    "    #f_outf=os.path.join(g_dir_out,os.path.basename(l_name))\n",
    "    #l_ResIm.save(f_outf)\n",
    "    \n",
    "    #print('saved '+f_outf)\n",
    "    return np.array(dst_im44)  \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pechen():\n",
    "    fnames,x_original1,y_region1,y_classif1=get_pictures2np(dir_reg='pechen1_reg',dir_100='pechen224')\n",
    "    print (\"loaded shape:\",x_original1.shape,y_region1.shape)\n",
    "    Xcolor1,ycolor1,yclassif1=get_transformedData(p_x_orig=x_original1,p_y_reg=y_region1,p_y_classif=y_classif1)\n",
    "    print (\"transformed shape:\",Xcolor1.shape,ycolor1.shape,yclassif1.shape)\n",
    "    \n",
    "    X_out1 = ycolor1.reshape((Xcolor1.shape[0], -1))\n",
    "    print (X_out1.shape)\n",
    "    #print(fnames)\n",
    "    return Xcolor1,X_out1,Xcolor1,ycolor1,fnames,x_original1,y_region1,y_classif1,yclassif1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_conduk():\n",
    "    fnames,x_original1,y_region1,y_classif1=get_pictures2np(dir_100='conduk',dir_reg='',p_width_from=0.7)\n",
    "    print (\"loaded shape:\",x_original1.shape,y_region1.shape)\n",
    "    Xcolor1,ycolor1,yclassif1=get_transformedData(p_x_orig=x_original1,p_y_reg=y_region1,p_y_classif=y_classif1)\n",
    "    print (\"transformed shape:\",Xcolor1.shape,ycolor1.shape,yclassif1.shape)\n",
    "    \n",
    "    X_out1 = ycolor1.reshape((Xcolor1.shape[0], -1))\n",
    "    print (X_out1.shape)\n",
    "    #print(fnames)\n",
    "    return Xcolor1,X_out1,Xcolor1,ycolor1,fnames,x_original1,y_region1,y_classif1,yclassif1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0->  conduk/ac-off-03.jpg 11 [1, 1, 1]\n",
      "1->  conduk/ac-off26.jpg 11 [1, 1, 1]\n",
      "2->  conduk/ac-on7.jpg 10 [1, 1, 1]\n",
      "3->  conduk/ac-off21.jpg 11 [1, 1, 1]\n",
      "4->  conduk/ac-off.png 11 [1, 1, 1]\n",
      "5->  conduk/ac-off5.jpg 11 [1, 1, 1]\n",
      "6->  conduk/ac-off6.jpg 11 [1, 1, 1]\n",
      "7->  conduk/ac-off.3png 11 [1, 1, 1]\n",
      "8->  conduk/ac-on.png 10 [1, 1, 1]\n",
      "9->  conduk/ac-off24.jpg 11 [1, 1, 1]\n",
      "10->  conduk/ac-off34.jpg 11 [1, 1, 1]\n",
      "11->  conduk/ac-off-01.jpg 11 [1, 1, 1]\n",
      "12->  conduk/ac-off22.jpg 11 [1, 1, 1]\n",
      "13->  conduk/ac-on4.jpg 10 [1, 1, 1]\n",
      "14->  conduk/ac-off12.jpg 11 [1, 1, 1]\n",
      "15->  conduk/ac-on-01.jpg 10 [1, 1, 1]\n",
      "16->  conduk/ac-on.-03jpg 10 [1, 1, 1]\n",
      "17->  conduk/ac-off9.jpg 11 [1, 1, 1]\n",
      "18->  conduk/ac-off32.jpg 11 [1, 1, 1]\n",
      "19->  conduk/ac-on-03.jpg 10 [1, 1, 1]\n",
      "20->  conduk/ac-on.jpg 10 [1, 1, 1]\n",
      "21->  conduk/ac-on6.jpg 10 [1, 1, 1]\n",
      "22->  conduk/ac-off18.jpg 11 [1, 1, 1]\n",
      "23->  conduk/ac-off33.jpg 11 [1, 1, 1]\n",
      "24->  conduk/ac-on20.jpg 10 [1, 1, 1]\n",
      "25->  conduk/ac-on2.jpg 10 [1, 1, 1]\n",
      "26->  conduk/ac-off25.jpg 11 [1, 1, 1]\n",
      "27->  conduk/ac-off.jpg 11 [1, 1, 1]\n",
      "28->  conduk/ac-off23.jpg 11 [1, 1, 1]\n",
      "29->  conduk/ac-on9.png 10 [1, 1, 1]\n",
      "30->  conduk/ac-off31.jpg 11 [1, 1, 1]\n",
      "31->  conduk/ac-off15.jpg 11 [1, 1, 1]\n",
      "32->  conduk/ac-off14.jpg 11 [1, 1, 1]\n",
      "33->  conduk/ac-off11.jpg 11 [1, 1, 1]\n",
      "34->  conduk/ac-on22.jpg 10 [1, 1, 1]\n",
      "35->  conduk/ac-on-02.jpg 10 [1, 1, 1]\n",
      "36->  conduk/ac-off28.jpg 11 [1, 1, 1]\n",
      "37->  conduk/ac-off27.jpg 11 [1, 1, 1]\n",
      "38->  conduk/ac-off-02.jpg 11 [1, 1, 1]\n",
      "39->  conduk/ac-off16.jpg 11 [1, 1, 1]\n",
      "40->  conduk/ac-off17.jpg 11 [1, 1, 1]\n",
      "41->  conduk/ac-on29.jpg 10 [1, 1, 1]\n",
      "42->  conduk/ac-off30.jpg 11 [1, 1, 1]\n",
      "43->  conduk/ac-on8.jpg 10 [1, 1, 1]\n",
      "44->  conduk/ac-off4.jpg 11 [1, 1, 1]\n",
      "45->  conduk/ac-off7.jpg 11 [1, 1, 1]\n",
      "loaded shape: (46, 100, 280, 3) (46, 100, 280, 3)\n",
      "transformed shape: (460, 3, 100, 280) (460, 3, 100, 280) (460, 2)\n",
      "(460, 84000)\n"
     ]
    }
   ],
   "source": [
    "region_width = 280\n",
    "region_height = 100\n",
    "g_split_lines = 1\n",
    "g_split_cols = 1\n",
    "\n",
    "an_min=-5\n",
    "an_max=5\n",
    "\n",
    "g_mode=3 # color mode 2 without black\n",
    "g_colors=3\n",
    "G_trash=1 #trashhold input picture\n",
    "G_trash_learn=1 #trashhold learn picture\n",
    "g_zca_mode=0 #whitening enabled\n",
    "g_zca_epsilon=0.1\n",
    "\n",
    "\n",
    "g_conv_num_filters = 16\n",
    "g_filter_size = 3\n",
    "g_pool_size = 2\n",
    "g_dense_mid_size = 256\n",
    "g_stride=1\n",
    "g_encode_size = 32\n",
    "g_ill='all'\n",
    "fn_weight='conduk.pkl'\n",
    "g_last_layerC2D=(((region_width-(g_filter_size-g_stride))/g_stride-(g_filter_size-g_stride))/g_stride/g_pool_size-(g_filter_size-g_stride))/g_stride/g_pool_size\n",
    "g_max_epochs=500\n",
    "g_dir_out='canduk_out'\n",
    "\n",
    "Xcolor,X_out,Xcolor_test,ycolor,fnames,x_original,y_region,y_classif0,y_classif=load_conduk()\n",
    "#fnames,x_original1,y_region1,y_classif1=get_pictures2np(dir_100='conduk',dir_reg='',p_width_from=0.5)\n",
    "#plt.figure(figsize=(15,15)) \n",
    "#sub4 = plt.subplot(1, 3, 1)\n",
    "#plt.imshow(x_original1[nn], cmap='gray')\n",
    "#sub4 = plt.subplot(1, 3, 2)\n",
    "#plt.imshow(y_region1[nn], cmap='gray')\n",
    "\n",
    "\n",
    "#nt (\"loaded shape:\",x_original1.shape,y_region1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_width = 28\n",
    "region_height = 28\n",
    "g_split_lines = 8\n",
    "g_split_cols = 8\n",
    "\n",
    "an_min=-3\n",
    "an_max=3\n",
    "\n",
    "g_mode=3 # color mode 2 without black\n",
    "g_colors=3\n",
    "G_trash=1 #trashhold input picture\n",
    "G_trash_learn=1 #trashhold learn picture\n",
    "g_zca_mode=0 #whitening enabled\n",
    "g_zca_epsilon=0.1\n",
    "\n",
    "\n",
    "g_conv_num_filters = 16\n",
    "g_filter_size = 3\n",
    "g_pool_size = 2\n",
    "g_dense_mid_size = 256\n",
    "g_stride=1\n",
    "g_encode_size = 32\n",
    "g_ill='all'\n",
    "fn_weight='conv_ae_medical200_'+g_ill+'ColorReg.pkl'\n",
    "g_last_layerC2D=(((region_width-(g_filter_size-g_stride))/g_stride-(g_filter_size-g_stride))/g_stride/g_pool_size-(g_filter_size-g_stride))/g_stride/g_pool_size\n",
    "g_max_epochs=500\n",
    "g_dir_out='medical_out'\n",
    "\n",
    "Xcolor,X_out,Xcolor_test,ycolor,fnames,x_original,y_region,y_classif=load_pechen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 280, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdd7d790610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAB4CAYAAACD3QEGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVtQIIYQQQgghJDFYUSOEEEIIIYSQxPh/d57G/OK+mXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd7d9e5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn=2\n",
    "plt.figure(figsize=(15,15)) \n",
    "im_in=GetPicture(Xcolor,p_nn=nn,p_angle=0)\n",
    "im_learn=GetPicture(X_out,p_nn=nn)\n",
    "print(im_in.shape)\n",
    "if g_colors==1:\n",
    "    sub4 = plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.array(im_in), cmap='gray')\n",
    "    sub4 = plt.subplot(1, 3, 2)\n",
    "    plt.imshow(np.array(im_learn), cmap='gray')\n",
    "else:\n",
    "    sub4 = plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.array(im_in))\n",
    "    sub4 = plt.subplot(1, 3, 2)\n",
    "    plt.imshow(np.array(im_learn))\n",
    "sub4 = plt.subplot(1, 3, 3)\n",
    "plt.imshow(x_original[nn], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://danielnouri.org/notes/category/deep-learning/\n",
    "#import theano\n",
    "#def float32(k):\n",
    "#    return np.cast['float32'](k)\n",
    "#https://www.kaggle.com/askrotov/predict-west-nile-virus/simple-lasagne-nn/run/13201\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, variable, target, half_life=10):\n",
    "        self.variable = variable\n",
    "        self.target = target\n",
    "        self.half_life = half_life\n",
    "    def __call__(self, nn, train_history):\n",
    "        delta = self.variable.get_value() - self.target\n",
    "        delta /= 2**(1.0/self.half_life)\n",
    "        self.variable.set_value(np.float32(self.target + delta))\n",
    "\n",
    "class LinearAdjustVariable(object):\n",
    "    \"\"\"\n",
    "        Adjusts a variable after each epoch, e.g. learning_rate or momentum\n",
    "        name : name of the variable to update\n",
    "        start : start value for update\n",
    "        stop : stop value for update\n",
    "    \"\"\"\n",
    "    def __init__(self, name, start=0.1, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "\n",
    "        # TODO: make custom stepfuction, exponential etc.\n",
    "        self.step_function = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = self.start\n",
    "        stepsize = 0.4 * (self.start - self.stop) / nn.max_epochs\n",
    "        if self.start < 0.1:\n",
    "            new_value -= stepsize * epoch  # np.float32(self.ls[epoch-1])\n",
    "            new_value = max(new_value, self.stop)\n",
    "        else:\n",
    "            new_value += stepsize * epoch\n",
    "            new_value = min(new_value, self.stop)\n",
    "\n",
    "        new_value = np.float32(new_value)\n",
    "        #print('im here '+self.name)\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "\n",
    "class EarlyStopper(object):\n",
    "    \"\"\"\n",
    "        Stops learning if there was no improvement for N iterations\n",
    "        max_iterations : number of iterations to have no improvement in a row\n",
    "                         before stopping\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iterations=10):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.best_iteration_score = 10000\n",
    "        self.best_iteration = 0\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.best_iteration_score > train_history[-1]['valid_loss']:\n",
    "            self.best_iteration_score = train_history[-1]['valid_loss']\n",
    "            self.best_iteration = len(train_history)\n",
    "\n",
    "        if len(train_history) - self.best_iteration >= self.max_iterations:\n",
    "            nn.max_epochs = train_history[-1]['epoch']\n",
    "\n",
    "\n",
    "class CustomValidationSet(object):\n",
    "    \"\"\"\n",
    "        Pass a custom validation set and a metric, standart is log_loss\n",
    "        validation_items: pass items in the form [('name1', [test_x, test_y]),\n",
    "                                                  ('name2',...)]]\n",
    "    \"\"\"\n",
    "    def __init__(self, validation_items=None, metric=log_loss):\n",
    "        self.validation_items = validation_items\n",
    "        self.metric = metric\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.validation_items is None:\n",
    "            return\n",
    "        for name, data in self.validation_items:\n",
    "            data_x, data_y = data\n",
    "            print('Validating {name}: {score}'.format(\n",
    "                name=name, score=self.metric(data_y, nn.predict_proba(data_x))))\n",
    "\n",
    "\n",
    "class TrainRatioStopper(object):\n",
    "    \"\"\"\n",
    "        Stops learning if train_loss/validation_loss falls below a certain ratio\n",
    "        stop_ratio : the train_loss/validation_loss ratio to stop training\n",
    "    \"\"\"\n",
    "    def __init__(self, stop_ratio=0.8):\n",
    "        self.stop_ratio = stop_ratio\n",
    "    def __call__(self, nn, train_history):\n",
    "        ratio = train_history[-1]['train_loss'] / \\\n",
    "            train_history[-1]['valid_loss']\n",
    "        if ratio < self.stop_ratio:\n",
    "            nn.max_epochs = train_history[-1]['epoch']\n",
    "\n",
    "\n",
    "class BestIterationSaver(object):\n",
    "    \"\"\"\n",
    "        Saves the weights for the best iteration\n",
    "        name : name of the best iteration weights file\n",
    "        delayed_start : number of iterations to wait before starting to save\n",
    "        verbose : print a logmessage when saving\n",
    "    \"\"\"\n",
    "    def __init__(self, name='best_iteration.weights', delayed_start=10, verbose=0):\n",
    "        self.best_score = None\n",
    "        self.best_weights = None\n",
    "        self.delayed_start = delayed_start\n",
    "        self.filename = name\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if len(train_history) < self.delayed_start:\n",
    "            return\n",
    "        if self.best_score is None or train_history[-1]['valid_loss'] < self.best_score:\n",
    "            if self.verbose:\n",
    "                print('Saving to {filename}'.format(filename=self.filename))\n",
    "            self.best_score = train_history[-1]['valid_loss']\n",
    "            nn.save_weights_to(self.filename)\n",
    "\n",
    "            \n",
    "class Save4Animate(object):\n",
    "    \"\"\"\n",
    "        Saves the weights for the best iteration\n",
    "        name : name of the best iteration weights file\n",
    "        delayed_start : number of iterations to wait before starting to save\n",
    "        verbose : print a logmessage when saving\n",
    "    \"\"\"\n",
    "    def __init__(self, layer='deconv2D2',prefix='animate', verbose=1,p_nn=1,p_angle=0):\n",
    "        self.prefix = prefix\n",
    "        self.verbose = verbose\n",
    "        self.c_layer =layer\n",
    "        self.N_image=p_nn\n",
    "        self.angle=p_angle\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.verbose:\n",
    "            print('Saving for animate  {layer} {epoch}'.format(layer=self.c_layer, epoch=len(train_history)))\n",
    "        lll=predictLayersToFile(p_net=nn,p_layerName=self.c_layer,p_Xcolor=Xcolor,p_nn=self.N_image,p_angle=self.angle,N_epoch=len(train_history))\n",
    "\n",
    "\n",
    "class MyOnbatch(object):\n",
    "    \"\"\"\n",
    "        Saves the weights for the best iteration\n",
    "        name : name of the best iteration weights file\n",
    "        delayed_start : number of iterations to wait before starting to save\n",
    "        verbose : print a logmessage when saving\n",
    "    \"\"\"\n",
    "    def __init__(self, layer='deconv2D2',prefix='animate', verbose=1,p_nn=1,p_angle=0):\n",
    "        self.prefix = prefix\n",
    "        self.verbose = verbose\n",
    "        self.c_layer =layer\n",
    "        self.N_image=p_nn\n",
    "        self.angle=p_angle\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        print ('its batch iterate ')\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "conv_num_filters = g_conv_num_filters\n",
    "filter_size = g_filter_size\n",
    "pool_size = g_pool_size\n",
    "encode_size = g_encode_size\n",
    "dense_mid_size = g_dense_mid_size\n",
    "stride=g_stride\n",
    "learning_rate = theano.shared(np.float32(0.1))\n",
    "momentum =   theano.shared(np.float32(0.975))\n",
    "\n",
    "\n",
    "\n",
    "layers_classif = [\n",
    "    (InputLayer, {'name': 'input1','shape': (None, Xcolor.shape[1], Xcolor.shape[2], Xcolor.shape[3])}), \n",
    "    (Conv2DLayerFast, {'name': 'conv2D1','num_filters': 32, 'filter_size': (5,5), \\\n",
    "                       \"nonlinearity\":rectify}),\n",
    "    (MaxPool2DLayerFast, {'name': 'maxpool1','pool_size': (2, 2)}),\n",
    "    (Conv2DLayerFast, {'name': 'conv2D2','num_filters': 32, 'filter_size': (5,5), \\\n",
    "                       \"nonlinearity\": rectify}),\n",
    "    (MaxPool2DLayerFast, {'name': 'maxpool2','pool_size': (2, 2)}),\n",
    "    (DropoutLayer, {'name': 'dropout1',\"p\": .5}), \n",
    "    (DenseLayer, {'name': 'hidden1','num_units': 256, \"nonlinearity\": rectify}),\n",
    "    (DropoutLayer, {'name': 'dropout2',\"p\": .5}), \n",
    "    (DenseLayer, {'name': 'output1','num_units': g_classifall, \"nonlinearity\": softmax}),\n",
    "]\n",
    "\n",
    "pad_in = 'valid'\n",
    "pad_out = 'full'\n",
    "\n",
    "layers = [\n",
    "    (InputLayer, {'name': 'input','shape': (None, Xcolor.shape[1], Xcolor.shape[2], Xcolor.shape[3])}), \n",
    "    (Conv2DLayerFast, {'name': 'conv2D1','num_filters': conv_num_filters, 'filter_size': filter_size, 'stride': stride,  'pad': pad_in}),\n",
    "    (Conv2DLayerFast, {'name': 'conv2D2','num_filters': conv_num_filters, 'filter_size': filter_size, 'stride': stride, 'pad': pad_in}),\n",
    "    (MaxPool2DLayerFast, {'name': 'maxpool1','pool_size': pool_size}),\n",
    "    #(Pool2DLayer, {'name': 'maxpool1','pool_size': pool_size,'mode': 'average_exc_pad'}),\n",
    "    (Conv2DLayerFast, {'name': 'conv2D3','num_filters': 2*conv_num_filters, 'filter_size': filter_size, 'stride': stride, 'pad': pad_in}),\n",
    "    #(Pool2DLayer, {'name': 'maxpool2','pool_size': pool_size,'mode': 'average_exc_pad'}),\n",
    "    (MaxPool2DLayerFast, {'name': 'maxpool2','pool_size': pool_size}),\n",
    "    (ReshapeLayer, {'name': 'reshapei','shape': (([0], -1))}),\n",
    "    (DenseLayer, {'name': 'encode_midi','num_units': dense_mid_size}),\n",
    "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
    "    (DenseLayer, {'name': 'encode_mido','num_units': dense_mid_size}),\n",
    "    (DenseLayer, {'name': 'encode_dense','num_units': 2*conv_num_filters*g_last_layerC2D* g_last_layerC2D}),\n",
    "    (ReshapeLayer, {'name': 'reshapeo','shape': (([0], 2*conv_num_filters, g_last_layerC2D, g_last_layerC2D))}),\n",
    "    (Upscale2DLayer, {'name': 'unpool2','scale_factor': pool_size}),\n",
    "    (Conv2DLayerSlow, {'name': 'deconv2D3','num_filters': conv_num_filters, 'filter_size': filter_size, 'stride': stride, 'pad': pad_out}),\n",
    "    (Upscale2DLayer, {'name': 'unpool1','scale_factor': pool_size}),\n",
    "    (Conv2DLayerSlow, {'name': 'deconv2D2','num_filters': conv_num_filters, 'filter_size': filter_size, 'stride': stride, 'pad': pad_out}),\n",
    "    (Conv2DLayerSlow, {'name': 'deconv2D1','num_filters': g_colors, 'filter_size': filter_size, 'stride': stride, 'pad': pad_out}),\n",
    "    (ReshapeLayer, {'name': 'output','shape': (([0], -1))}),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ae = NeuralNet(\n",
    "    layers=layers,\n",
    "    max_epochs=g_max_epochs,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=learning_rate,\n",
    "    #update_learning_rate=0.025,\n",
    "    #update_momentum=0.975,\n",
    "    update_momentum=momentum,\n",
    "    on_epoch_finished = [\n",
    "        #LinearAdjustVariable('update_learning_rate', start=0.05, stop=0.0001),\n",
    "        #LinearAdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        #TrainRatioStopper(0.8),\n",
    "        #EarlyStopper(),\n",
    "        #BestIterationSaver(verbose=0),\n",
    "        Save4Animate(layer='conv2D1',prefix='animate', verbose=0,p_nn=4,p_angle=0),\n",
    "        Save4Animate(layer='conv2D2',prefix='animate', verbose=0,p_nn=4,p_angle=0),\n",
    "        Save4Animate(layer='conv2D3',prefix='animate', verbose=0,p_nn=4,p_angle=0),\n",
    "        Save4Animate(layer='deconv2D3',prefix='animate', verbose=0,p_nn=4,p_angle=0),\n",
    "        Save4Animate(layer='deconv2D2',prefix='animate', verbose=0,p_nn=4,p_angle=0),\n",
    "        Save4Animate(layer='deconv2D1',prefix='animate', verbose=0,p_nn=4,p_angle=0)\n",
    "        \n",
    "        ],\n",
    "    \n",
    "    #on_batch_finished= [\n",
    "    #    MyOnbatch(layer='deconv2D1',prefix='animate', verbose=0,p_nn=4,p_angle=0)\n",
    "    #    ],\n",
    "\n",
    "    regression=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "ae_classif = NeuralNet(\n",
    "    layers=layers_classif,\n",
    "    max_epochs=g_max_epochs,\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.001,\n",
    "    update_momentum=0.9,\n",
    "    on_epoch_finished = [\n",
    "        Save4Animate(layer='conv2D1',prefix='animate', verbose=0,p_nn=2,p_angle=0),\n",
    "        Save4Animate(layer='conv2D2',prefix='animate', verbose=0,p_nn=2,p_angle=0),\n",
    "        BestIterationSaver(verbose=1,name='best_conduk.weights', delayed_start=50),\n",
    "        ],\n",
    "    regression=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 12103842 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  ---------\n",
      "  0  input1    3x100x280\n",
      "  1  conv2D1   32x96x276\n",
      "  2  maxpool1  32x48x138\n",
      "  3  conv2D2   32x44x134\n",
      "  4  maxpool2  32x22x67\n",
      "  5  dropout1  32x22x67\n",
      "  6  hidden1   256\n",
      "  7  dropout2  256\n",
      "  8  output1   2\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  ------\n",
      "      1       \u001b[36m0.25623\u001b[0m       \u001b[32m0.23012\u001b[0m      1.11346  31.72s\n",
      "      2       \u001b[36m0.22968\u001b[0m       \u001b[32m0.21858\u001b[0m      1.05078  33.90s\n",
      "      3       \u001b[36m0.22362\u001b[0m       0.22111      1.01136  33.74s\n",
      "      4       0.22400       0.22235      1.00740  32.98s\n",
      "      5       0.22483       0.21996      1.02215  31.67s\n",
      "      6       \u001b[36m0.22101\u001b[0m       \u001b[32m0.21736\u001b[0m      1.01680  31.76s\n",
      "      7       \u001b[36m0.21844\u001b[0m       \u001b[32m0.21601\u001b[0m      1.01128  31.63s\n",
      "      8       \u001b[36m0.21786\u001b[0m       \u001b[32m0.21551\u001b[0m      1.01088  31.65s\n",
      "      9       \u001b[36m0.21038\u001b[0m       \u001b[32m0.21442\u001b[0m      0.98115  31.68s\n",
      "     10       0.21906       \u001b[32m0.21318\u001b[0m      1.02760  31.68s\n",
      "     11       0.21430       \u001b[32m0.21204\u001b[0m      1.01064  31.69s\n",
      "     12       0.21634       \u001b[32m0.21066\u001b[0m      1.02697  31.65s\n",
      "     13       0.21235       \u001b[32m0.20969\u001b[0m      1.01265  31.71s\n",
      "     14       0.21503       \u001b[32m0.20853\u001b[0m      1.03117  31.66s\n",
      "     15       \u001b[36m0.20643\u001b[0m       \u001b[32m0.20642\u001b[0m      1.00005  31.71s\n",
      "     16       0.20896       \u001b[32m0.20468\u001b[0m      1.02094  31.67s\n",
      "     17       0.20679       \u001b[32m0.20312\u001b[0m      1.01806  31.75s\n",
      "     18       0.21602       \u001b[32m0.20134\u001b[0m      1.07292  31.72s\n",
      "     19       \u001b[36m0.20000\u001b[0m       \u001b[32m0.19951\u001b[0m      1.00249  31.67s\n",
      "     20       \u001b[36m0.19621\u001b[0m       \u001b[32m0.19768\u001b[0m      0.99257  31.74s\n",
      "     21       0.20349       \u001b[32m0.19560\u001b[0m      1.04035  31.70s\n",
      "     22       \u001b[36m0.18834\u001b[0m       \u001b[32m0.19284\u001b[0m      0.97667  31.67s\n",
      "     23       0.19588       \u001b[32m0.18966\u001b[0m      1.03277  34.22s\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 434110464 bytes of device memory (out of memory).\nApply node that caused the error: GpuDownsampleFactorMaxGrad{(2, 2),True}(GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, GpuDownsampleFactorMax{(2, 2),True}.0, GpuCorrMM_gradInputs{valid, (1, 1)}.0)\nToposort index: 87\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]\nInputs shapes: [(128, 32, 96, 276), (128, 32, 48, 138), (128, 32, 48, 138)]\nInputs strides: [(847872, 26496, 276, 1), (211968, 6624, 138, 1), (211968, 6624, 138, 1)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDownsampleFactorMaxGrad{(2, 2),True}.0, GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e0297edfb0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mg_max_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mae_classif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXcolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_classif\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnolearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_iterator_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m                 batch_train_loss = self.apply_batch_func(\n\u001b[1;32m--> 587\u001b[1;33m                     self.train_iter_, Xb, yb)\n\u001b[0m\u001b[0;32m    588\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_train_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/nolearn/lasagne/base.pyc\u001b[0m in \u001b[0;36mapply_batch_func\u001b[1;34m(func, Xb, yb)\u001b[0m\n\u001b[0;32m    644\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    909\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/igor/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 434110464 bytes of device memory (out of memory).\nApply node that caused the error: GpuDownsampleFactorMaxGrad{(2, 2),True}(GpuElemwise{Composite{(i0 * (i1 + Abs(i1)))},no_inplace}.0, GpuDownsampleFactorMax{(2, 2),True}.0, GpuCorrMM_gradInputs{valid, (1, 1)}.0)\nToposort index: 87\nInputs types: [CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 4D)]\nInputs shapes: [(128, 32, 96, 276), (128, 32, 48, 138), (128, 32, 48, 138)]\nInputs strides: [(847872, 26496, 276, 1), (211968, 6624, 138, 1), (211968, 6624, 138, 1)]\nInputs values: ['not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + (i0 * i1 * sgn(i2)))}}[(0, 1)](CudaNdarrayConstant{[[[[ 0.5]]]]}, GpuDownsampleFactorMaxGrad{(2, 2),True}.0, GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "#print(y_classif)\n",
    "g_max_epochs=10000\n",
    "\n",
    "ae_classif.fit(Xcolor,y_classif)\n",
    "pickle.dump(ae, open(fn_weight,'wb'))\n",
    "from nolearn.lasagne.visualize import plot_loss\n",
    "plot_loss(ae_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g_max_epochs=500\n",
    "ae.fit(Xcolor, X_out)\n",
    "pickle.dump(ae, open(fn_weight,'wb'))\n",
    "\n",
    "from nolearn.lasagne.visualize import plot_loss\n",
    "plot_loss(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae = pickle.load(open(fn_weight,'rb'))\n",
    "#pickle.dump(ae, open('conv_ae_medical400_class2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn=1\n",
    "n_plot=30\n",
    "\n",
    "for x_idx in range(n_plot):\n",
    "    nn=x_idx+0\n",
    "    print(nn,\"->\",fnames[nn])\n",
    "    plt.figure(figsize=(20,20)) \n",
    "    dst_im = PredictByWholeImgFull(p_Xcolor=Xcolor,p_nn=nn)\n",
    "    dst_im_merge=MergePredict_Original(x_original[nn],dst_im)\n",
    "\n",
    "    sub1 = plt.subplot(1, 4,1)\n",
    "    if g_colors==1:\n",
    "        plt.imshow( x_original[nn].reshape(x_original[nn].shape[0],x_original[nn].shape[1]), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow( x_original[nn])\n",
    "    sub1.set_title(\"orig\")\n",
    "\n",
    "    sub2 = plt.subplot(1, 4, 2)\n",
    "    if g_colors==1:\n",
    "        plt.imshow(y_region[nn].reshape(x_original[nn].shape[0],x_original[nn].shape[1]), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(y_region[nn]/256.)\n",
    "    sub2.set_title(\"learn\")\n",
    "\n",
    "    sub3 = plt.subplot(1, 4, 3)\n",
    "    plt.imshow(dst_im, cmap='gray')\n",
    "    sub3.set_title(\"predict\")\n",
    "    if  g_mode<2:\n",
    "        sub4 = plt.subplot(1, 4, 4)\n",
    "        plt.imshow(dst_im_merge)\n",
    "        sub4.set_title(\"merged\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nolearn.lasagne import visualize\n",
    "visualize.plot_conv_weights(ae.layers_['conv2D3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lll=predictLayersToFile(p_net=ae,p_layerName='deconv2D2',p_Xcolor=Xcolor,p_nn=4,p_angle=0,N_epoch=1)\n",
    "plt.imshow(lll,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lll=predictLayer(p_net=ae,p_layerName='deconv2D3',p_Xcolor=Xcolor,p_nn=1,p_angle=0,p_layerFrom=9,p_layers=1)\n",
    "plt.imshow(lll,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) \n",
    "print(x_original[nn].shape)\n",
    "#v1=np.rollaxis(x_original[nn], 2, 0)\n",
    "print(x_original[nn].shape)\n",
    "v1=x_original[nn]\n",
    "res=np.clip(zca_whitening_color(v1,epsilon = 0.01 )*256.,0,255).astype('uint8')\n",
    "print(v1.shape)\n",
    "v2=v1.reshape(v1.shape[0],v1.shape[1])\n",
    "print(v2.shape)\n",
    "sub4 = plt.subplot(1, 2, 1)\n",
    "if g_colors==1:\n",
    "    plt.imshow(v1.reshape(v1.shape[0],v1.shape[1]), cmap='gray')\n",
    "else:\n",
    "    plt.imshow(np.array(v1), cmap='gray')\n",
    "sub4 = plt.subplot(1, 2, 2)\n",
    "plt.imshow(res, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_layers(ae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#e = pickle.load(open('conv_ae_medical224_7_BWIn.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(fnames )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x11, value in np.ndenumerate(fnames):\n",
    "    if 'meta' in value:\n",
    "         print ([x11[0],value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (not not '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[[1,2,4],[3,4,5]]\n",
    "b=np.array(a)\n",
    "print (b.shape)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1=[[1],[3]]\n",
    "b1=np.array(a1)\n",
    "\n",
    "print (b1.shape)\n",
    "print (b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1=b1\n",
    "print (c1)\n",
    "c1=np.hstack((c1,b1))\n",
    "c1=np.hstack((c1,b1))\n",
    "print (c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_widthF=850\n",
    "p_width_from=0.5\n",
    "p_width_delta=0.3\n",
    "print(l_widthF-l_widthF*p_width_from)\n",
    "print(l_widthF-l_widthF*p_width_from+l_widthF*p_width_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " plt.imshow(Image.open('conduk/ac-on6.jpg').crop((450,0,850,99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d[8]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
